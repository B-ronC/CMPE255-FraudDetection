{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline Models\n",
        "\n",
        "Testing Logistic Regression and Random Forest as baselines before moving to more complex models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "sys.path.append('..')\n",
        "from utils.metrics import *\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = '../data/processed/'\n",
        "\n",
        "if os.path.exists(DATA_PATH + 'X_train.pkl'):\n",
        "    X_train = pd.read_pickle(DATA_PATH + 'X_train.pkl')\n",
        "    X_val = pd.read_pickle(DATA_PATH + 'X_val.pkl')\n",
        "    X_test = pd.read_pickle(DATA_PATH + 'X_test.pkl')\n",
        "    y_train = pd.read_pickle(DATA_PATH + 'y_train.pkl')\n",
        "    y_val = pd.read_pickle(DATA_PATH + 'y_val.pkl')\n",
        "    y_test = pd.read_pickle(DATA_PATH + 'y_test.pkl')\n",
        "    print(\"Loaded preprocessed data\")\n",
        "else:\n",
        "    # temp preprocessing until 02_preprocessing is done\n",
        "    print(\"Preprocessed data not found, doing temp preprocessing...\")\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    \n",
        "    df = pd.read_csv('../data/creditcard.csv')\n",
        "    \n",
        "    # chronological split\n",
        "    train_end = int(len(df) * 0.70)\n",
        "    val_end = int(len(df) * 0.85)\n",
        "    \n",
        "    train_df = df.iloc[:train_end].copy()\n",
        "    val_df = df.iloc[train_end:val_end].copy()\n",
        "    test_df = df.iloc[val_end:].copy()\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    train_df['Amount_scaled'] = scaler.fit_transform(train_df[['Amount']])\n",
        "    val_df['Amount_scaled'] = scaler.transform(val_df[['Amount']])\n",
        "    test_df['Amount_scaled'] = scaler.transform(test_df[['Amount']])\n",
        "    \n",
        "    feat_cols = [f'V{i}' for i in range(1, 29)] + ['Amount_scaled']\n",
        "    \n",
        "    X_train, y_train = train_df[feat_cols], train_df['Class']\n",
        "    X_val, y_val = val_df[feat_cols], val_df['Class']\n",
        "    X_test, y_test = test_df[feat_cols], test_df['Class']\n",
        "\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "print(f\"Fraud rate: {y_train.mean()*100:.3f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=SEED)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "lr_pred = lr.predict(X_val)\n",
        "lr_prob = lr.predict_proba(X_val)[:, 1]\n",
        "lr_metrics = calculate_all_metrics(y_val, lr_pred, lr_prob)\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "for k, v in lr_metrics.items():\n",
        "    print(f\"  {k}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_val, lr_pred, 'Logistic Regression')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_pr_roc_curves(y_val, lr_prob, 'Logistic Regression')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', \n",
        "                            random_state=SEED, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "rf_pred = rf.predict(X_val)\n",
        "rf_prob = rf.predict_proba(X_val)[:, 1]\n",
        "rf_metrics = calculate_all_metrics(y_val, rf_pred, rf_prob)\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "for k, v in rf_metrics.items():\n",
        "    print(f\"  {k}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_val, rf_pred, 'Random Forest')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# feature importance\n",
        "feat_imp = pd.DataFrame({'feature': X_train.columns, 'importance': rf.feature_importances_})\n",
        "feat_imp = feat_imp.sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feat_imp.head(15), x='importance', y='feature')\n",
        "plt.title('Top 15 Features')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_metrics_table({\n",
        "    'Logistic Regression': lr_metrics,\n",
        "    'Random Forest': rf_metrics\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_multiple_pr_curves({'LR': lr_prob, 'RF': rf_prob}, y_val)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('../models', exist_ok=True)\n",
        "\n",
        "joblib.dump(lr, '../models/lr_baseline.joblib')\n",
        "joblib.dump(rf, '../models/rf_baseline.joblib')\n",
        "\n",
        "results = {\n",
        "    'y_val': y_val,\n",
        "    'lr_prob': lr_prob, 'rf_prob': rf_prob,\n",
        "    'lr_metrics': lr_metrics, 'rf_metrics': rf_metrics\n",
        "}\n",
        "joblib.dump(results, '../models/baseline_results.joblib')\n",
        "print(\"saved\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
