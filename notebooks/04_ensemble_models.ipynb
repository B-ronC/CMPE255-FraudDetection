{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensemble Models\n",
        "\n",
        "Comparing tuned RF, XGBoost, LightGBM, and CatBoost.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "sys.path.append('..')\n",
        "from utils.metrics import *\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = '../data/processed/'\n",
        "\n",
        "if os.path.exists(DATA_PATH + 'X_train.pkl'):\n",
        "    X_train = pd.read_pickle(DATA_PATH + 'X_train.pkl')\n",
        "    X_val = pd.read_pickle(DATA_PATH + 'X_val.pkl')\n",
        "    X_test = pd.read_pickle(DATA_PATH + 'X_test.pkl')\n",
        "    y_train = pd.read_pickle(DATA_PATH + 'y_train.pkl')\n",
        "    y_val = pd.read_pickle(DATA_PATH + 'y_val.pkl')\n",
        "    y_test = pd.read_pickle(DATA_PATH + 'y_test.pkl')\n",
        "else:\n",
        "    # temp preprocessing\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    df = pd.read_csv('../data/creditcard.csv')\n",
        "    \n",
        "    train_end = int(len(df) * 0.70)\n",
        "    val_end = int(len(df) * 0.85)\n",
        "    \n",
        "    train_df = df.iloc[:train_end].copy()\n",
        "    val_df = df.iloc[train_end:val_end].copy()\n",
        "    test_df = df.iloc[val_end:].copy()\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    train_df['Amount_scaled'] = scaler.fit_transform(train_df[['Amount']])\n",
        "    val_df['Amount_scaled'] = scaler.transform(val_df[['Amount']])\n",
        "    test_df['Amount_scaled'] = scaler.transform(test_df[['Amount']])\n",
        "    \n",
        "    feat_cols = [f'V{i}' for i in range(1, 29)] + ['Amount_scaled']\n",
        "    X_train, y_train = train_df[feat_cols], train_df['Class']\n",
        "    X_val, y_val = val_df[feat_cols], val_df['Class']\n",
        "    X_test, y_test = test_df[feat_cols], test_df['Class']\n",
        "\n",
        "# for class imbalance\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "print(f\"Train: {len(X_train)}, scale_pos_weight: {scale_pos_weight:.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest (Tuned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "}\n",
        "\n",
        "t0 = time.time()\n",
        "rf_search = RandomizedSearchCV(\n",
        "    RandomForestClassifier(class_weight='balanced', random_state=SEED, n_jobs=-1),\n",
        "    rf_params, n_iter=15, cv=cv, scoring='average_precision', random_state=SEED, n_jobs=-1\n",
        ")\n",
        "rf_search.fit(X_train, y_train)\n",
        "rf_time = time.time() - t0\n",
        "\n",
        "print(f\"RF done in {rf_time:.0f}s, best score: {rf_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = rf_search.best_estimator_\n",
        "rf_prob = rf.predict_proba(X_val)[:, 1]\n",
        "rf_pred = rf.predict(X_val)\n",
        "rf_metrics = calculate_all_metrics(y_val, rf_pred, rf_prob)\n",
        "print(rf_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8],\n",
        "    'colsample_bytree': [0.7, 0.8],\n",
        "}\n",
        "\n",
        "t0 = time.time()\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=SEED, \n",
        "                  use_label_encoder=False, eval_metric='aucpr', n_jobs=-1),\n",
        "    xgb_params, n_iter=15, cv=cv, scoring='average_precision', random_state=SEED, n_jobs=-1\n",
        ")\n",
        "xgb_search.fit(X_train, y_train)\n",
        "xgb_time = time.time() - t0\n",
        "\n",
        "print(f\"XGB done in {xgb_time:.0f}s, best: {xgb_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb = xgb_search.best_estimator_\n",
        "xgb_prob = xgb.predict_proba(X_val)[:, 1]\n",
        "xgb_pred = xgb.predict(X_val)\n",
        "xgb_metrics = calculate_all_metrics(y_val, xgb_pred, xgb_prob)\n",
        "print(xgb_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LightGBM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lgb_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [5, 7, -1],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'num_leaves': [31, 50],\n",
        "    'subsample': [0.7, 0.8],\n",
        "}\n",
        "\n",
        "t0 = time.time()\n",
        "lgb_search = RandomizedSearchCV(\n",
        "    LGBMClassifier(scale_pos_weight=scale_pos_weight, random_state=SEED, verbose=-1, n_jobs=-1),\n",
        "    lgb_params, n_iter=15, cv=cv, scoring='average_precision', random_state=SEED, n_jobs=-1\n",
        ")\n",
        "lgb_search.fit(X_train, y_train)\n",
        "lgb_time = time.time() - t0\n",
        "\n",
        "print(f\"LGB done in {lgb_time:.0f}s, best: {lgb_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lgb = lgb_search.best_estimator_\n",
        "lgb_prob = lgb.predict_proba(X_val)[:, 1]\n",
        "lgb_pred = lgb.predict(X_val)\n",
        "lgb_metrics = calculate_all_metrics(y_val, lgb_pred, lgb_prob)\n",
        "print(lgb_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CatBoost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_params = {\n",
        "    'iterations': [100, 200],\n",
        "    'depth': [4, 6, 8],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'l2_leaf_reg': [1, 3, 5],\n",
        "}\n",
        "\n",
        "t0 = time.time()\n",
        "cat_search = RandomizedSearchCV(\n",
        "    CatBoostClassifier(scale_pos_weight=scale_pos_weight, random_state=SEED, verbose=False),\n",
        "    cat_params, n_iter=15, cv=cv, scoring='average_precision', random_state=SEED, n_jobs=-1\n",
        ")\n",
        "cat_search.fit(X_train, y_train)\n",
        "cat_time = time.time() - t0\n",
        "\n",
        "print(f\"Cat done in {cat_time:.0f}s, best: {cat_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat = cat_search.best_estimator_\n",
        "cat_prob = cat.predict_proba(X_val)[:, 1]\n",
        "cat_pred = cat.predict(X_val)\n",
        "cat_metrics = calculate_all_metrics(y_val, cat_pred, cat_prob)\n",
        "print(cat_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare All\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_metrics = {\n",
        "    'RF': rf_metrics,\n",
        "    'XGB': xgb_metrics, \n",
        "    'LGB': lgb_metrics,\n",
        "    'Cat': cat_metrics\n",
        "}\n",
        "print_metrics_table(all_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "probs = {'RF': rf_prob, 'XGB': xgb_prob, 'LGB': lgb_prob, 'Cat': cat_prob}\n",
        "plot_multiple_pr_curves(probs, y_val)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_multiple_roc_curves(probs, y_val)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# confusion matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "plot_confusion_matrix(y_val, rf_pred, 'RF', axes[0,0])\n",
        "plot_confusion_matrix(y_val, xgb_pred, 'XGB', axes[0,1])\n",
        "plot_confusion_matrix(y_val, lgb_pred, 'LGB', axes[1,0])\n",
        "plot_confusion_matrix(y_val, cat_pred, 'Cat', axes[1,1])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pick best by auc-pr\n",
        "best_name = max(all_metrics.keys(), key=lambda x: all_metrics[x]['auc_pr'])\n",
        "print(f\"Best model: {best_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('../models', exist_ok=True)\n",
        "\n",
        "joblib.dump(rf, '../models/rf_tuned.joblib')\n",
        "joblib.dump(xgb, '../models/xgb_tuned.joblib')\n",
        "joblib.dump(lgb, '../models/lgb_tuned.joblib')\n",
        "joblib.dump(cat, '../models/cat_tuned.joblib')\n",
        "\n",
        "results = {\n",
        "    'y_val': y_val,\n",
        "    'rf_prob': rf_prob, 'xgb_prob': xgb_prob, \n",
        "    'lgb_prob': lgb_prob, 'cat_prob': cat_prob,\n",
        "    'rf_metrics': rf_metrics, 'xgb_metrics': xgb_metrics,\n",
        "    'lgb_metrics': lgb_metrics, 'cat_metrics': cat_metrics,\n",
        "    'best': best_name,\n",
        "    'times': {'rf': rf_time, 'xgb': xgb_time, 'lgb': lgb_time, 'cat': cat_time}\n",
        "}\n",
        "joblib.dump(results, '../models/ensemble_results.joblib')\n",
        "print(\"done\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
